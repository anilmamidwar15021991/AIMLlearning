{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#006a79; font-size:40px'> Evaluation Metrics for Classification</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic to be covered  - \n",
    "1. [Accuracy](#1)\n",
    "1. [Confusion Metric](#2)\n",
    "1. [Accuracy, Precision, Recall, F-1 score](#3)\n",
    "1. [Sensitivity, Specificity and Detection Rate](#4)\n",
    "1. [ROC curve](#5) \n",
    "1. [AUC](#6)\n",
    "1. [Gini's coeffecient](#7)\n",
    "1. [KS Statistics](#8)\n",
    "1. [Brier Score Loss](#9)\n",
    "1. [Log Loss or cross entropy loss](#10)\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Churn Modelling</h2>\n",
    "</div>\n",
    "\n",
    "**Goal :** To predict if a customer has left the bank(closed his/her account) or he/she continues to be a customer\n",
    "\n",
    "**Data :** The data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he/she continues to be a customer.\n",
    "\n",
    "Before going into details of handling imbalanced data let's load the churn modelling data and make it ready for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report, accuracy_score, roc_auc_score, plot_roc_curve\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 800)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = pd.read_csv('Datasets/Churn_Modelling.csv',index_col='RowNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "RowNumber                                                                     \n",
       "1            15634602  Hargrave          619    France  Female   42       2   \n",
       "2            15647311      Hill          608     Spain  Female   41       1   \n",
       "3            15619304      Onio          502    France  Female   42       8   \n",
       "4            15701354      Boni          699    France  Female   39       1   \n",
       "5            15737888  Mitchell          850     Spain  Female   43       2   \n",
       "\n",
       "             Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber                                                        \n",
       "1               0.00              1          1               1   \n",
       "2           83807.86              1          0               1   \n",
       "3          159660.80              3          1               0   \n",
       "4               0.00              2          0               0   \n",
       "5          125510.82              1          1               1   \n",
       "\n",
       "           EstimatedSalary  Exited  \n",
       "RowNumber                           \n",
       "1                101348.88       1  \n",
       "2                112542.58       0  \n",
       "3                113931.57       1  \n",
       "4                 93826.63       0  \n",
       "5                 79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have loaded the data, you need to pre process it before building the model. Hence let's pre process it\n",
    "#### Data pre - processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop few columns which won't contribute to the model using domain knowldedge.\n",
    "churn_data.drop(['CustomerId','Surname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do one hot encoding for the column `Geo` as Logistic Regression model would be expecting numeric features\n",
    "churn_data = pd.get_dummies(prefix='Geo',data=churn_data,columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than using one hot encoding we can do label encoding as well. Here let's use replace function rather than label encoder\n",
    "churn_data = churn_data.replace(to_replace={'Gender': {'Female': 1,'Male':0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geo_France</th>\n",
       "      <th>Geo_Germany</th>\n",
       "      <th>Geo_Spain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "RowNumber                                                               \n",
       "1                  619       1   42       2       0.00              1   \n",
       "2                  608       1   41       1   83807.86              1   \n",
       "3                  502       1   42       8  159660.80              3   \n",
       "4                  699       1   39       1       0.00              2   \n",
       "5                  850       1   43       2  125510.82              1   \n",
       "\n",
       "           HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geo_France  \\\n",
       "RowNumber                                                                   \n",
       "1                  1               1        101348.88       1           1   \n",
       "2                  0               1        112542.58       0           0   \n",
       "3                  1               0        113931.57       1           1   \n",
       "4                  0               0         93826.63       0           1   \n",
       "5                  1               1         79084.10       0           0   \n",
       "\n",
       "           Geo_Germany  Geo_Spain  \n",
       "RowNumber                          \n",
       "1                    0          0  \n",
       "2                    0          1  \n",
       "3                    0          0  \n",
       "4                    0          0  \n",
       "5                    0          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the y variable series and x variables dataset\n",
    "X = churn_data.drop(['Exited'],axis=1)\n",
    "y = churn_data.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling because yes we don't want one independent variable dominating the other and it makes computations easy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting target values on x_test dataset\n",
    "y_predicted = lr.predict(X_test)\n",
    "y_predicted_prob = lr.predict_proba(X_test)\n",
    "y_predicted_prob = [x[1] for x in y_predicted_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075757575757576\n"
     ]
    }
   ],
   "source": [
    "# Checking the performance of logistic regression model\n",
    "score_lr = lr.score(X_test, y_test)\n",
    "print(score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metric\n",
    "- https://www.ritchieng.com/machine-learning-evaluate-classification-model/\n",
    "- https://www.machinelearningplus.com/machine-learning/evaluation-metrics-classification-models-r/\n",
    "- https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "- https://dzone.com/articles/calculating-auc-and-gini-model-metrics-for-logisti\n",
    "- https://heartbeat.fritz.ai/classification-model-evaluation-90d743883106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>1. Accuracy</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8075757575757576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "actual = y_test\n",
    "predicted = y_predicted \n",
    "accuracy = accuracy_score(actual, predicted) \n",
    "\n",
    "\n",
    "print('Accuracy :' ,accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>2. Confusion Metric</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[2511  106]\n",
      " [ 529  154]]\n"
     ]
    }
   ],
   "source": [
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "\n",
    "actual = y_test\n",
    "predicted = y_predicted \n",
    "results = confusion_matrix(actual, predicted) \n",
    "\n",
    "\n",
    "print ('Confusion Matrix :')\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>3. Accuracy Precision Recall F1 Score</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8075757575757576\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      2617\n",
      "           1       0.59      0.23      0.33       683\n",
      "\n",
      "    accuracy                           0.81      3300\n",
      "   macro avg       0.71      0.59      0.61      3300\n",
      "weighted avg       0.78      0.81      0.77      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy Score :',accuracy_score(actual, predicted) )\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h4 style='margin:10px 5px'> Inferences:</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary` :\n",
    "\n",
    "Total number of classes predicted correctly is called `accuracy`.\n",
    "\n",
    "The approach here is to find what percentage of the model’s positive (1’s) predictions are accurate. This is nothing but `Precision`.\n",
    "\n",
    "Let’s suppose you have a model with high precision, I also want to know what percentage of ALL 1’s were covered. This can be captured using Sensitivity.\n",
    "\n",
    "But in this context, it is known as `Recall`. Just because, it is customary to call them together as `Precision and Recall`.\n",
    "\n",
    "A high precision score gives more confidence to the model’s capability to classify 1’s. Combining this with Recall gives an idea of how many of the total 1’s it was able to cover.\n",
    "\n",
    "A good model should have a good precision as well as a high recall. So ideally, I want to have a measure that combines both these aspects in one single metric – the `F1 Score`.\n",
    "\n",
    "   **F1 Score = (2 * Precision * Recall) / (Precision + Recall)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>4. Sensitivity, Specificity and Detection Rate</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metric\n",
      "[[2511  106]\n",
      " [ 529  154]] \n",
      "\n",
      "Accuracy or Detection Rate\n",
      "0.8075757575757576\n",
      "0.8075757575757576 \n",
      "\n",
      "Classification Error\n",
      "0.19242424242424241\n",
      "0.1924242424242424 \n",
      "\n",
      "Sensitivity\n",
      "0.5923076923076923 \n",
      "\n",
      "Specificity\n",
      "0.8259868421052632\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(\"Confusion Metric\")\n",
    "print(confusion,  \"\\n\")\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[1, 0]\n",
    "FN = confusion[0, 1]\n",
    "\n",
    "\n",
    "# Classification Accuracy \n",
    "\n",
    "# use float to perform true division, not integer division\n",
    "print(\"Accuracy or Detection Rate\")\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_predicted), \"\\n\")\n",
    "\n",
    "# Classification Error\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "print(\"Classification Error\")\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_predicted), \"\\n\")\n",
    "\n",
    "# Sensitivity\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"Sensitivity\")\n",
    "print(sensitivity, \"\\n\")\n",
    "\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity\")\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h4 style='margin:10px 5px'> Inferences:</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary : `\n",
    "Sensitivity is the percentage of actual 1’s that were correctly predicted. It shows what percentage of 1’s were covered by the model.\n",
    "\n",
    "The total number of 1’s is 260 out of which 154 was correctly predicted. So, sensitivity is 154/260 = 59.23%\n",
    "\n",
    "Sensitivity matters more when classifying the 1’s correctly is more important than classifying the 0’s. Just like what we need here in churn case, where you don’t want to miss out any churned customer to be classified as ‘not churned’.\n",
    "\n",
    "Likewise, Specificity is the proportion of actual 0’s that were correctly predicted. So in this case, it is 2511 / (3040) = 82.59%.\n",
    "\n",
    "Specificity matters more when classifying the 0’s correctly is more important than classifying the 1’s.\n",
    "\n",
    "Maximizing specificity is more relevant in cases like spam detection, where you strictly don’t want genuine messages (0’s) to end up in spam (1’s).\n",
    "\n",
    "Detection rate is the proportion of the whole sample where the events were detected correctly. So, it is 2665 / 3300 = 80.75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>5. ROC curve</h2>\n",
    "</div>\n",
    "\n",
    "Often, choosing the best model is sort of a balance between predicting the one's accurately or the zeroes accurately. In other words sensitivity and specificity.\n",
    "\n",
    "But it would be great to have something that captures both these aspects in one single metric.\n",
    "\n",
    "This is nicely captured by the 'Receiver Operating Characteristics' curve, also called as the ROC curve. In fact, the area under the ROC curve can be used as an evaluation metric to compare the efficacy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_probs = lr.predict_proba(X_test)\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h4 style='margin:10px 5px'> Inferences:</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary : `\n",
    "\n",
    "Interpreting the ROC plot is very different from a regular line plot. Because, though there is an X and a Y-axis, you don't read it as: for an X value of 0.25, the Y value is .9.\n",
    "\n",
    "Instead, what we have here is a line that traces the probability cutoff from 1 at the bottom-left to 0 in the top right.\n",
    "\n",
    "This is a way of analyzing how the sensitivity and specificity perform for the full range of probability cutoffs, that is from 0 to 1.\n",
    "\n",
    "Ideally, if you have a perfect model, all the events will have a probability score of 1 and all non-events will have a score of 0. For such a model, the area under the ROC will be a perfect 1.\n",
    "\n",
    "So, if we trace the curve from bottom left, the value of probability cutoff decreases from 1 towards 0. If you have a good model, more of the real events should be predicted as events, resulting in high sensitivity and low FPR. In that case, the curve will rise steeply covering a large area before reaching the top-right.\n",
    "\n",
    "Therefore, the larger the area under the ROC curve, the better is your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>6. AUC</h2>\n",
    "</div>\n",
    "\n",
    "The area under ROC curve is known as AUC, it's values goes from 0.5 to 1, if somehow the value is less that 0.5, that means we are predicting in the wrong direction and we can alter the prediction outputs, hence the AUC would be 1 - AUC initial, now it would be greater than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.770\n"
     ]
    }
   ],
   "source": [
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>7. Gini's coeffecient</h2>\n",
    "</div>\n",
    "\n",
    "Gini Coefficient is an indicator of how well the model outperforms random predictions. It can be computed from the area under the ROC curve using the following formula:\n",
    "\n",
    "Gini Coefficient = (2 * AUROC) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5403855073063775\n"
     ]
    }
   ],
   "source": [
    "# Gini Coefficient = (2 * AUROC) - 1\n",
    "\n",
    "gini_coeff = 2*lr_auc - 1\n",
    "print(gini_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>8. KS Statistics</h2>\n",
    "</div>\n",
    "\n",
    "- https://www.listendata.com/2019/07/KS-Statistics-Python.html\n",
    "- https://statcompute.wordpress.com/2012/11/18/calculating-k-s-statistic-with-python/\n",
    "\n",
    "The KS Statistic and the KS Chart (discussed next) are used to make decisions like: How many customers to target for a marketing campaign? or How many customers should we pay for to show ads etc.\n",
    "\n",
    "So how to compute the Kolmogorov-Smirnov statistic?\n",
    "\n",
    "Step 1: Once the prediction probability scores are obtained, the observations are sorted by decreasing order of probability scores. This way, you can expect the rows at the top to be classified as 1 while rows at the bottom to be 0's.\n",
    "\n",
    "Step 2: All observations are then split into 10 equal sized buckets (bins).\n",
    "\n",
    "Step 3: Then, KS statistic is the maximum difference between the cumulative percentage of responders or 1's (cumulative true positive rate) and cumulative percentage of non-responders or 0's (cumulative false positive rate).\n",
    "\n",
    "The significance of KS statistic is, it helps to understand, what portion of the population should be targeted to get the highest response rate (1's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.4154259988329489, pvalue=3.3295809917944807e-85)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## KS 2 sample method\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "df = pd.DataFrame({\"prob\" : lr_probs, \"y_test\" : y_test})\n",
    "\n",
    "ks_2samp(df.loc[df.y_test==0,\"prob\"], df.loc[df.y_test==1,\"prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decline method\n",
    "\n",
    "def ks(data=None,target=None, prob=None):\n",
    "    data['target0'] = 1 - data[target]\n",
    "    data['bucket'] = pd.qcut(data[prob], 10)\n",
    "    grouped = data.groupby('bucket', as_index = False)\n",
    "    kstable = pd.DataFrame()\n",
    "    kstable['min_prob'] = grouped.min()[prob]\n",
    "    kstable['max_prob'] = grouped.max()[prob]\n",
    "    kstable['events']   = grouped.sum()[target]\n",
    "    kstable['nonevents'] = grouped.sum()['target0']\n",
    "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
    "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
    "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
    "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
    "\n",
    "    #Formating\n",
    "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
    "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
    "    kstable.index = range(1,11)\n",
    "    kstable.index.rename('Decile', inplace=True)\n",
    "    pd.set_option('display.max_columns', 9)\n",
    "    print(kstable)\n",
    "    \n",
    "    #Display KS\n",
    "    from colorama import Fore\n",
    "    print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
    "    return(kstable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        min_prob  max_prob  events  nonevents event_rate nonevent_rate  \\\n",
      "Decile                                                                   \n",
      "1       0.449141  0.901518     189        141     27.67%         5.39%   \n",
      "2       0.327272  0.449111     133        197     19.47%         7.53%   \n",
      "3       0.250397  0.327113     101        229     14.79%         8.75%   \n",
      "4       0.198122  0.250387      68        262      9.96%        10.01%   \n",
      "5       0.157623  0.198044      59        271      8.64%        10.36%   \n",
      "6       0.126395  0.157535      44        286      6.44%        10.93%   \n",
      "7       0.097064  0.126103      35        295      5.12%        11.27%   \n",
      "8       0.073180  0.096996      20        310      2.93%        11.85%   \n",
      "9       0.050555  0.073138      20        310      2.93%        11.85%   \n",
      "10      0.010758  0.050452      14        316      2.05%        12.07%   \n",
      "\n",
      "       cum_eventrate cum_noneventrate    KS  \n",
      "Decile                                       \n",
      "1             27.67%            5.39%  22.3  \n",
      "2             47.14%           12.92%  34.2  \n",
      "3             61.93%           21.67%  40.3  \n",
      "4             71.89%           31.68%  40.2  \n",
      "5             80.53%           42.03%  38.5  \n",
      "6             86.97%           52.96%  34.0  \n",
      "7             92.09%           64.23%  27.9  \n",
      "8             95.02%           76.08%  18.9  \n",
      "9             97.95%           87.93%  10.0  \n",
      "10           100.00%          100.00%   0.0  \n",
      "\u001b[31mKS is 40.300000000000004% at decile 3\n"
     ]
    }
   ],
   "source": [
    "mydf = ks(data=df,target=\"y_test\", prob=\"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary` : \n",
    "\n",
    "If KS is in top 3 decile and score above 40, it is considered a good predictive model. At the same time it is important to validate the model by checking other performance metrics as well to confirm that model is not suffering from overfitting problem.\n",
    "\n",
    "In our case it's 40.3 for 3rd decile, so we can say that the model is good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>9. Brier Score Loss</h2>\n",
    "</div>\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html\n",
    "\n",
    "The smaller the Brier score, the better, hence the naming with “loss”. Across all items in a set N predictions, the Brier score measures the mean squared difference between (1) the predicted probability assigned to the possible outcomes for item i, and (2) the actual outcome. Therefore, the lower the Brier score is for a set of predictions, the better the predictions are calibrated. Note that the Brier score always takes on a value between zero and one, since this is the largest possible difference between a predicted probability (which must be between zero and one) and the actual outcome (which can take on values of only 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1367893043461415"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "brier_score_loss(y_test, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary : `\n",
    "\n",
    "Brier Score is very less, so the model is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> <br>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>10. Log Loss or cross entropy loss</h2>\n",
    "</div>\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\n",
    "\n",
    "Log loss, aka logistic loss or cross-entropy loss.\n",
    "\n",
    "This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier’s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is\n",
    "\n",
    "-log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43117442486493035"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test,lr_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
